import csv
import os
from multiprocessing import Pool
from tqdm import tqdm
from .aggregate import Aggregate
from .shard import Shard
from .slice import Slice


class MachineUnlearning:
    """
    MachineUnlearning class to handle sharding, slicing, and training models for
    machine unlearning processes.

    Attributes:
        num_shard (int): Number of shards.
        num_slice (int): Number of slices.
        epochs (int): Number of epochs for training.
        dataset_path (str): Path to the dataset.
        shard (Shard): Instance of the Shard class.
        slice (Slice): Instance of the Slice class.
        aggregate (Aggregate): Instance of the Aggregate class.
        sisa_file (str): Path to the SISA description file.
    """

    def __init__(self, dataset_path, num_shard, num_slice, epochs, sisa_file):
        """
        Initialize the MachineUnlearning class with dataset path, shard and slice numbers,
        epochs, and SISA file path.

        Args:
            dataset_path (str): Path to the dataset.
            num_shard (int): Number of shards.
            num_slice (int): Number of slices.
            epochs (int): Number of epochs for training.
            sisa_file (str): Path to the SISA description file.

        Raises:
            ValueError: If num_shard or num_slice is less than 1.
        """
        if num_shard < 1 or num_slice < 1:
            raise ValueError("num_shard and num_slice should be greater than 0")
        self.num_shard = num_shard
        self.num_slice = num_slice
        self.epochs = max(epochs, num_slice)
        self.dataset_path = dataset_path
        self.shard = Shard(self.num_shard)
        self.slice = Slice(self.num_slice)
        self.aggregate = Aggregate()
        self.sisa_file = sisa_file

    def init_model(self, train_method, dataset_path, model_dir):
        """
        Initialize the model by sharding and slicing the dataset, then training the model.

        Args:
            train_method (function): Method to train the model.
            dataset_path (str): Path to the dataset.
            model_dir (str): Directory to save the trained model.

        Raises:
            Exception: If an error occurs during model initialization.
        """
        try:
            sharded_list = self.shard.divide_by_shard(dataset_path)
            sliced_list = [
                self.slice.divide_by_slice(sublist) for sublist in sharded_list
            ]
            self.save_sisa_description(sliced_list, self.sisa_file)
            epochs_per_slice = self.epochs // len(sliced_list)
            trained_epochs = 0
            with Pool() as pool:
                results = []
                for i, sublist in enumerate(
                    tqdm(sliced_list, desc="Training Shards")
                ):
                    for j, subsublist in enumerate(sublist):
                        epoch_num = (
                            self.epochs - trained_epochs
                            if j == len(subsublist) - 1
                            else epochs_per_slice
                        )
                        result = pool.apply_async(
                            train_method,
                            args=(self.sisa_file, epoch_num, model_dir, i, j),
                        )
                        results.append(result)
                        trained_epochs += epoch_num
                [result.get() for result in results]
        except Exception as e:
            print(f"An error occurred during model initialization: {e}")

    def save_sisa_description(self, sliced_list, output_file):
        """
        Save the SISA description to a file.

        Args:
            sliced_list (list): List of sliced data.
            output_file (str): Path to the output file.

        Raises:
            Exception: If an error occurs while saving SISA description.
        """
        try:
            with open(output_file, "w", newline="") as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(["data_file", "shard_index", "slice_index"])
                for i, sublist in enumerate(sliced_list):
                    for j, subsublist in enumerate(sublist):
                        for data_file in subsublist:
                            writer.writerow([data_file, i, j])
        except Exception as e:
            print(f"An error occurred while saving SISA description: {e}")

    def load_sisa_description(self, input_file):
        """
        Load the SISA description from a file.

        Args:
            input_file (str): Path to the input file.

        Returns:
            list: Loaded SISA description as a list.

        Raises:
            Exception: If an error occurs while loading SISA description.
        """
        sliced_list = []
        try:
            with open(input_file, "r", newline="") as csvfile:
                reader = csv.reader(csvfile)
                next(reader)  # Skip header row
                for row in reader:
                    shard_index = int(row[1])
                    slice_index = int(row[2])
                    while len(sliced_list) <= shard_index:
                        sliced_list.append([])
                    while len(sliced_list[shard_index]) <= slice_index:
                        sliced_list[shard_index].append([])
                    sliced_list[shard_index][slice_index].append(row[0])
        except Exception as e:
            print(f"An error occurred while loading SISA description: {e}")
        return sliced_list

    def add_data_point(
        self, train_method, add_data_files, dataset_path, model_dir
    ):
        """
        Add data points to the dataset, update the SISA description, and retrain the model.

        Args:
            train_method (function): Method to train the model.
            add_data_files (list): List of data files to add.
            dataset_path (str): Path to the dataset.
            model_dir (str): Directory to save the trained model.

        Raises:
            Exception: If an error occurs while adding data points.
        """
        try:
            sliced_list = self.load_sisa_description(self.sisa_file)
            new_sharded_list, updated_shard_indices = (
                self.shard.distribute_files(sliced_list, add_data_files)
            )
            result = [
                self.slice.append_files(sublist, add_data_files)
                for sublist in new_sharded_list
            ]
            new_sliced_list, updated_slice_indices = zip(*result)
            self.save_sisa_description(new_sliced_list, self.sisa_file)
            epochs_per_slice = self.epochs // len(new_sliced_list)
            trained_epochs = 0
            with Pool() as pool:
                results = []
                for i, sublist in enumerate(
                    tqdm(new_sliced_list, desc="Retraining Shards")
                ):
                    for j, subsublist in enumerate(sublist):
                        epoch_num = (
                            self.epochs - trained_epochs
                            if j == len(subsublist) - 1
                            else epochs_per_slice
                        )
                        result = pool.apply_async(
                            train_method,
                            args=(self.sisa_file, epoch_num, model_dir, i, j),
                        )
                        results.append(result)
                        trained_epochs += epoch_num
                [result.get() for result in results]
        except Exception as e:
            print(f"An error occurred while adding data points: {e}")

    def delete_data_point(
        self, train_method, delete_data_files, dataset_path, model_dir
    ):
        """
        Delete data points from the dataset, update the SISA description, and retrain the model.

        Args:
            train_method (function): Method to train the model.
            delete_data_files (list): List of data files to delete.
            dataset_path (str): Path to the dataset.
            model_dir (str): Directory to save the trained model.

        Raises:
            Exception: If an error occurs while deleting data points.
        """
        try:
            sliced_list = self.load_sisa_description(self.sisa_file)
            for data_file in delete_data_files:
                for sublist in sliced_list:
                    for subsublist in sublist:
                        if data_file in subsublist:
                            subsublist.remove(data_file)
            self.save_sisa_description(sliced_list, self.sisa_file)
            # Retrain only the affected shards
            updated_shards = set()
            for data_file in delete_data_files:
                for shard_index, shard in enumerate(sliced_list):
                    for slice_index, slice in enumerate(shard):
                        if data_file in slice:
                            updated_shards.add((shard_index, slice_index))
            epochs_per_slice = self.epochs // len(sliced_list)
            trained_epochs = 0
            with Pool() as pool:
                results = []
                for shard_index, slice_index in updated_shards:
                    epoch_num = (
                        self.epochs - trained_epochs
                        if slice_index == len(sliced_list[shard_index]) - 1
                        else epochs_per_slice
                    )
                    result = pool.apply_async(
                        train_method,
                        args=(
                            self.sisa_file,
                            epoch_num,
                            model_dir,
                            shard_index,
                            slice_index,
                        ),
                    )
                    results.append(result)
                    trained_epochs += epoch_num
                [result.get() for result in results]
        except Exception as e:
            print(f"An error occurred while deleting data points: {e}")

    def predict(self, model_dir, predict_data_files, predict_method):
        """
        Predict the output for the given data files using the trained model.

        Args:
            model_dir (str): Directory where the trained model is saved.
            predict_data_files (list): List of data files to predict.
            predict_method (function): Method to make predictions.

        Returns:
            list: Final prediction result.

        Raises:
            Exception: If an error occurs during prediction.
        """
        try:
            model_path_list = self.aggregate.get_model_path_list(model_dir)
            predictions = []
            for model_path in model_path_list:
                prediction = predict_method(predict_data_files, model_path)
                predictions.append(prediction)
            final_prediction = self.aggregate.vote(predictions)
            return final_prediction
        except Exception as e:
            print(f"An error occurred during prediction: {e}")
            return None
