import os

import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm

from utils.npy_dataset import NpyDataset
from utils.resize import ResizeAndPad1DTo2D


class DataProcessor:
    """
    Process the dataset and load it into PyTorch DataLoader.
    """

    def __init__(self, dataset_dir):
        self.dataset_dir = dataset_dir

    def get_transform(self, model_image_size):
        """
        Get the transformation for the dataset.
        """
        return transforms.Compose(
            [
                ResizeAndPad1DTo2D(model_image_size),
                transforms.ToPILImage(),
                transforms.ToTensor(),
            ]
        )

    def get_num_classes(data_description_path, label_column_name):
        """
        Get the number of classes in the dataset based on the label column in the CSV file.

        Parameters:
            data_description_path (str): The path to the CSV file describing the dataset.
            label_column_name (str): The name of the column containing the labels.

        Returns:
            int: The number of unique labels (classes) in the dataset.
        """
        df = pd.read_csv(data_description_path)
        num_classes = df[label_column_name].nunique()
        return num_classes

    def get_data_loader(
        self,
        model,
        data_description_path,
        batch_size=32,
        train_ratio=0.7,
        val_ratio=0.2,
    ):
        """
        Load the dataset into PyTorch DataLoader.

        Args:
            model: The model which might have an image_size attribute.
            data_description_path (str): Path to the csv file with annotations.
            dataset_dir (str): Directory with all the .npy files.
            batch_size (int, optional): How many samples per batch to load. Default is 32.
            train_ratio (float, optional): Proportion of the dataset to include in the train split. Default is 0.7.
            val_ratio (float, optional): Proportion of the dataset to include in the validation split. Default is 0.2.

        Returns:
            tuple: (train_loader, val_loader, test_loader)
        """
        if hasattr(model, "image_size"):
            transform = self.get_transform(model.image_size)
        else:
            transform = transforms.Compose([transforms.ToTensor()])

        dataset = NpyDataset(
            csv_file=data_description_path,
            root_dir=self.dataset_dir,
            transform=transform,
        )

        train_size = int(train_ratio * len(dataset))
        val_size = int(val_ratio * len(dataset))
        test_size = len(dataset) - train_size - val_size

        train_data, val_data, test_data = random_split(
            dataset, [train_size, val_size, test_size]
        )

        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)
        for data, labels in train_loader:
            print(data.shape)
            print(labels.shape)
        for data, labels in val_loader:
            print(data.shape)
            print(labels.shape)
        for data, labels in test_loader:
            print(data.shape)
            print(labels.shape)
        return train_loader, val_loader, test_loader


class ModelTrainer:
    """
    Train and evaluate the model.
    """

    def __init__(self, model, metrics_manager, device, learning_rate=0.001, epochs=10):
        self.model = model.to(device)
        self.device = device
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.criterion = nn.CrossEntropyLoss()
        self.epochs = epochs
        self.metrics_manager = metrics_manager

    def train(self, train_loader, val_loader, model_dir):
        """
        Train the model.

        # TODO epoch should be set at model not here
        """
        for epoch in range(self.epochs):
            self.model.train()
            train_losses = []
            all_preds, all_labels = [], []
            progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}")
            for inputs, labels in progress_bar:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                self.optimizer.zero_grad()
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                loss.backward()
                self.optimizer.step()
                train_losses.append(loss.item())
                _, preds = torch.max(outputs, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                progress_bar.set_postfix(loss=loss.item())
            # Save the model
            model_path = os.path.join(model_dir, f"model_{epoch + 1}.pth")
            torch.save(self.model.state_dict(), model_path)
            # Calculate training metrics
            train_accuracy = accuracy_score(all_labels, all_preds)
            train_precision = precision_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            train_recall = recall_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            train_f1 = f1_score(all_labels, all_preds, average="macro", zero_division=0)
            average_loss = sum(train_losses) / len(train_losses)
            # Record training metrics
            self.metrics_manager.record_metrics(
                epoch + 1,
                average_loss,
                train_accuracy,
                train_precision,
                train_recall,
                train_f1,
                "train",
            )

            # Evaluate on validation set
            self.evaluate(val_loader, epoch)

    def evaluate(self, val_loader, epoch):
        """
        Evaluate the model on the validation set.
        """
        self.model.eval()
        val_losses = []
        all_preds, all_labels = [], []
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                val_losses.append(loss.item())
                _, preds = torch.max(outputs.data, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

            val_accuracy = accuracy_score(all_labels, all_preds)
            val_precision = precision_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            val_recall = recall_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            val_f1 = f1_score(all_labels, all_preds, average="macro", zero_division=0)
            average_loss = sum(val_losses) / len(val_losses)

            # Record validation metrics
            self.metrics_manager.record_metrics(
                epoch + 1,
                average_loss,
                val_accuracy,
                val_precision,
                val_recall,
                val_f1,
                "validate",
            )

    def test(self, test_loader):
        """
        Test the model on the test set.
        """
        self.model.eval()
        test_losses = []
        all_preds, all_labels = [], []
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                test_losses.append(loss.item())
                _, preds = torch.max(outputs.data, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

            test_accuracy = accuracy_score(all_labels, all_preds)
            test_precision = precision_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            test_recall = recall_score(
                all_labels, all_preds, average="macro", zero_division=0
            )
            test_f1 = f1_score(all_labels, all_preds, average="macro", zero_division=0)
            average_loss = sum(test_losses) / len(test_losses)

            # Record test metrics
            self.metrics_manager.record_metrics(
                0,
                average_loss,
                test_accuracy,
                test_precision,
                test_recall,
                test_f1,
                "test",
            )
